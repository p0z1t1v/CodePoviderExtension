# ü§ñ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è LLM

> **–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è**: –Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (Claude, GPT, Gemini –∏ –¥—Ä.) —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –≤–µ–±-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

## üéØ –û–±–∑–æ—Ä –∑–∞–¥–∞—á–∏

**–¶–µ–ª—å**: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –æ–±—ä—ë–º–æ–≤ –≤–µ–±-–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, API-—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–±-—Ä–µ—Å—É—Ä—Å–æ–≤.

## üõ†Ô∏è –¢—Ä–µ–±—É–µ–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- ‚úÖ **–í–µ–±-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** (Playwright, Selenium, Puppeteer)
- ‚úÖ **–•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** (MCP memory, –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î, —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞)
- ‚úÖ **JavaScript –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ** –≤ –±—Ä–∞—É–∑–µ—Ä–µ
- ‚úÖ **–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞** —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü

### –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
- üîÑ **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
- üìä **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
- üß† **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫** –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
- üìù **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞** —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

## üìã –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º

### –§–∞–∑–∞ 1: –†–∞–∑–≤–µ–¥–∫–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# –ü—Å–µ–≤–¥–æ–∫–æ–¥ –¥–ª—è –ª—é–±–æ–π LLM
def analyze_target_site(start_url):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞ –∏ –ø–ª–∞–Ω–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞
    """
    # 1. –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    navigate_to(start_url)
    
    # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    navigation_patterns = extract_navigation_structure()
    
    # 3. –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏
    all_links = discover_all_documentation_links()
    
    # 4. –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º
    unique_links = filter_and_deduplicate(all_links)
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–ª–∞–Ω –ø–∞—Ä—Å–∏–Ω–≥–∞
    save_parsing_plan(unique_links, navigation_patterns)
    
    return unique_links
```

### –§–∞–∑–∞ 2: –ú–∞—Å—Å–æ–≤—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö

```python
def execute_mass_parsing(links_list, storage_config):
    """
    –í—ã–ø–æ–ª–Ω—è–µ–º –º–∞—Å—Å–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    """
    results = []
    
    for i, url in enumerate(links_list):
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –ª–∏ —É–∂–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            if is_already_processed(url, storage_config):
                log(f"[{i+1}/{len(links_list)}] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {url} - —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                continue
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page_data = parse_single_page(url)
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            structured_data = structure_content(page_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            save_to_storage(structured_data, storage_config)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            log(f"[{i+1}/{len(links_list)}] ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {page_data.title}")
            
            # –ü–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            sleep(1)
            
        except Exception as error:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {url}: {error}")
            continue
    
    return results
```

### –§–∞–∑–∞ 3: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

```python
def validate_and_analyze_results(storage_config):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = get_storage_statistics(storage_config)
    
    # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = find_duplicate_content(storage_config)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –ø–æ–∫—Ä—ã—Ç–∏—è
    coverage_report = analyze_coverage(storage_config)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    final_report = generate_final_report(stats, duplicates, coverage_report)
    
    return final_report
```

## üöÄ –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

### –î–ª—è MCP (Model Context Protocol)

```javascript
// –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è MCP my-memory
class MCPDocumentationParser {
    constructor(projectId) {
        this.projectId = projectId;
    }
    
    async parseDocumentationSite(startUrl) {
        // 1. –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏
        const links = await this.collectAllLinks(startUrl);
        
        // 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        for (const [index, url] of links.entries()) {
            await this.processSinglePage(url, index + 1, links.length);
        }
        
        // 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
        return await this.generateReport();
    }
    
    async collectAllLinks(startUrl) {
        await playwright_navigate(startUrl);
        
        const links = await playwright_evaluate(`
            Array.from(document.querySelectorAll('a[href*="documentation"]'))
                .map(a => a.href)
                .filter(href => href.includes('your-target-domain'))
                .filter((href, i, arr) => arr.indexOf(href) === i)
        `);
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–µ—Å—Ç—Ä —Å—Å—ã–ª–æ–∫
        await mcp_memory_SaveProjectArtifact({
            title: "–†–µ–µ—Å—Ç—Ä —Å—Å—ã–ª–æ–∫ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞",
            type: "Reference",
            content: JSON.stringify(links, null, 2),
            projectId: this.projectId,
            tags: "parsing,links,registry"
        });
        
        return links;
    }
    
    async processSinglePage(url, index, total) {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        const existing = await mcp_memory_SearchProjectArtifacts({
            query: url,
            projectId: this.projectId,
            maxResults: 1
        });
        
        if (existing.length > 0) {
            console.log(`[${index}/${total}] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º ${url} - —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω`);
            return;
        }
        
        // –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        await playwright_navigate(url);
        const content = await playwright_get_visible_text();
        const title = await playwright_evaluate(`
            document.querySelector('h1')?.textContent || 
            document.title.split(' | ')[0]
        `);
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º
        await mcp_memory_SaveProjectArtifact({
            title: title,
            type: "Document",
            content: `# ${title}\n\n**–ò—Å—Ç–æ—á–Ω–∏–∫:** ${url}\n\n${content}`,
            projectId: this.projectId,
            tags: "documentation,auto-parsed,web-content"
        });
        
        console.log(`[${index}/${total}] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: ${title}`);
    }
}
```

### –î–ª—è —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã

```python
# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
import os
import json
import hashlib
from urllib.parse import urlparse

class FileSystemDocumentationParser:
    def __init__(self, output_dir):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(f"{output_dir}/pages", exist_ok=True)
        os.makedirs(f"{output_dir}/meta", exist_ok=True)
    
    def parse_documentation_site(self, start_url):
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏
        links = self.collect_all_links(start_url)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–µ—Å—Ç—Ä
        with open(f"{self.output_dir}/meta/links_registry.json", 'w', encoding='utf-8') as f:
            json.dump(links, f, ensure_ascii=False, indent=2)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        for i, url in enumerate(links):
            self.process_single_page(url, i + 1, len(links))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å
        self.generate_content_index()
    
    def process_single_page(self, url, index, total):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        safe_name = self.url_to_filename(url)
        filename = f"{safe_name}_{url_hash}.md"
        
        file_path = f"{self.output_dir}/pages/{filename}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ —É–∂–µ
        if os.path.exists(file_path):
            print(f"[{index}/{total}] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {url} - —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
            return
        
        # –ü–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ (–∑–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∞—à–∏ –≤–µ–±-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã)
        title, content = self.extract_page_content(url)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º markdown
        markdown_content = f"""# {title}

**–ò—Å—Ç–æ—á–Ω–∏–∫:** {url}  
**–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {datetime.now().isoformat()}

---

{content}
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"[{index}/{total}] ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {title}")
    
    def url_to_filename(self, url):
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º URL –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        parsed = urlparse(url)
        path_parts = parsed.path.strip('/').split('/')
        return '_'.join(part for part in path_parts if part)[:50]
```

### –î–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö

```python
# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Pinecone, Weaviate, ChromaDB –∏ –¥—Ä.
class VectorDBDocumentationParser:
    def __init__(self, vector_client, collection_name):
        self.vector_client = vector_client
        self.collection_name = collection_name
    
    def parse_with_embeddings(self, start_url):
        links = self.collect_all_links(start_url)
        
        for url in links:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–æ URL
            if self.document_exists(url):
                continue
            
            # –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç
            title, content = self.extract_page_content(url)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            embedding = self.generate_embedding(f"{title}\n{content}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
            self.vector_client.upsert([{
                'id': self.url_to_id(url),
                'values': embedding,
                'metadata': {
                    'title': title,
                    'url': url,
                    'content': content[:1000],  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
                    'full_content': content,
                    'parsed_at': datetime.now().isoformat()
                }
            }])
    
    def semantic_search(self, query, top_k=5):
        # –ü–æ–∏—Å–∫ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
        query_embedding = self.generate_embedding(query)
        results = self.vector_client.query(
            vector=query_embedding,
            top_k=top_k,
            include_metadata=True
        )
        return results
```

## üéõÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```json
{
  "parsing_config": {
    "target_site": "https://docs.example.com",
    "batch_size": 5,
    "delay_between_requests": 1000,
    "max_retries": 3,
    "timeout": 15000,
    "headless_mode": true
  },
  "content_filters": {
    "min_content_length": 100,
    "max_content_length": 50000,
    "exclude_patterns": ["login", "signup", "404"],
    "include_patterns": ["docs", "guide", "api", "tutorial"]
  },
  "storage_config": {
    "type": "mcp|filesystem|vectordb",
    "project_id": "DocumentationProject",
    "output_directory": "./parsed_docs",
    "chunk_size": 1000,
    "metadata_fields": ["title", "url", "tags", "parsed_at"]
  },
  "quality_control": {
    "check_duplicates": true,
    "validate_links": true,
    "generate_reports": true,
    "auto_cleanup": false
  }
}
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å

### –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫

```python
class ParsingMetrics:
    def __init__(self):
        self.stats = {
            'total_links_found': 0,
            'pages_processed': 0,
            'pages_skipped': 0,
            'errors_encountered': 0,
            'total_content_size': 0,
            'average_page_size': 0,
            'processing_time': 0,
            'start_time': None,
            'end_time': None
        }
    
    def log_progress(self, current, total, page_title=""):
        progress = (current / total) * 100
        print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {current}/{total} ({progress:.1f}%) - {page_title}")
    
    def generate_final_report(self):
        self.stats['end_time'] = datetime.now()
        self.stats['processing_time'] = (
            self.stats['end_time'] - self.stats['start_time']
        ).total_seconds()
        
        report = f"""
# üìà –û—Ç—á—ë—Ç –æ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

## –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü**: {self.stats['pages_processed']}
- **–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü**: {self.stats['pages_skipped']}
- **–û—à–∏–±–æ–∫**: {self.stats['errors_encountered']}
- **–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞**: {self.stats['total_content_size']:,} —Å–∏–º–≤–æ–ª–æ–≤
- **–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É**: {self.stats['processing_time'] / max(1, self.stats['pages_processed']):.2f} —Å–µ–∫—É–Ω–¥

## –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
- **–ù–∞—á–∞–ª–æ**: {self.stats['start_time']}
- **–û–∫–æ–Ω—á–∞–Ω–∏–µ**: {self.stats['end_time']}
- **–û–±—â–µ–µ –≤—Ä–µ–º—è**: {self.stats['processing_time']:.1f} —Å–µ–∫—É–Ω–¥

## –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
- **–£—Å–ø–µ—à–Ω–æ—Å—Ç—å**: {(self.stats['pages_processed'] / max(1, self.stats['total_links_found']) * 100):.1f}%
- **–°–∫–æ—Ä–æ—Å—Ç—å**: {self.stats['pages_processed'] / max(1, self.stats['processing_time'] / 3600):.1f} —Å—Ç—Ä–∞–Ω–∏—Ü/—á–∞—Å
"""
        return report
```

## üö® –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

### –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

```python
class RobustParser:
    def __init__(self, config):
        self.config = config
        self.failed_urls = []
        self.checkpoint_frequency = 10
    
    def parse_with_recovery(self, urls):
        for i, url in enumerate(urls):
            try:
                self.process_page_with_retries(url)
                
                # –°–æ–∑–¥–∞—ë–º —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ N —Å—Ç—Ä–∞–Ω–∏—Ü
                if i % self.checkpoint_frequency == 0:
                    self.save_checkpoint(i, urls[i:])
                    
            except Exception as e:
                self.handle_parsing_error(url, e)
                continue
    
    def process_page_with_retries(self, url, max_retries=3):
        for attempt in range(max_retries):
            try:
                return self.process_single_page(url)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –¥–ª—è {url}: {e}")
                time.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
    
    def resume_from_checkpoint(self, checkpoint_file):
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –º–µ—Å—Ç–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        with open(checkpoint_file, 'r') as f:
            remaining_urls = json.load(f)
        return remaining_urls
```

## üîç –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### 1. API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

```python
def parse_api_documentation(api_docs_url):
    """
    –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    """
    config = {
        'selectors': {
            'endpoint_title': 'h2, h3',
            'endpoint_description': '.description, .summary',
            'code_examples': 'pre code, .code-block',
            'parameters': '.parameters table, .params'
        },
        'structure': {
            'extract_examples': True,
            'preserve_code_formatting': True,
            'group_by_sections': True
        }
    }
    return config
```

### 2. –£—á–µ–±–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

```python
def parse_educational_content(course_url):
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    """
    config = {
        'content_types': ['lesson', 'tutorial', 'exercise', 'quiz'],
        'metadata_extraction': {
            'difficulty_level': '.difficulty, .level',
            'duration': '.duration, .time-to-complete',
            'prerequisites': '.prerequisites, .requirements'
        },
        'sequential_processing': True  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —É—Ä–æ–∫–æ–≤
    }
    return config
```

## üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–æ–≤–µ—Ç—ã

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ headless —Ä–µ–∂–∏–º** - —É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 2-3 —Ä–∞–∑–∞
2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã** - –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
3. **–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥—É–±–ª–∏–∫–∞—Ç—ã** –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
4. **–õ–æ–≥–∏—Ä—É–π—Ç–µ –ø—Ä–æ–≥—Ä–µ—Å—Å** –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
5. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É** –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä—ë–º–æ–≤
6. **–ö—ç—à–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
7. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤** (–ø–∞–º—è—Ç—å, CPU, —Å–µ—Ç—å)

### –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º

- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω –¥–æ—Å—Ç—É–ø –∫ —Ü–µ–ª–µ–≤–æ–º—É —Å–∞–π—Ç—É
- [ ] –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤–µ–±-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
- [ ] –°–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö
- [ ] –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ç–∞–π–º–∞—É—Ç—ã –∏ retry-–ø–æ–ª–∏—Ç–∏–∫–∏
- [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
- [ ] –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- [ ] –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø–ª–∞–Ω –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ–µ–≤

---

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–≠—Ç–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç **—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ª—é–±–æ–π LLM —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏.

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã**:
- üîÑ **–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å** - –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º
- üõ°Ô∏è **–ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- üìà **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –æ—Ç –µ–¥–∏–Ω–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ —Ü–µ–ª—ã—Ö —Å–∞–π—Ç–æ–≤
- üìä **–ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å** - –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞

–ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –∫–æ–¥ –ø–æ–¥ –≤–∞—à–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è!
